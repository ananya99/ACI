# @package _global_

# This task is similar to light_seeking, but has a goal _and_ adversary. The
# config must set `custom.frequency` to the frequency of the texture
# that should be applied to the objects. By default, the textures are synchronized
# between the goal and adversary, but this can be overridden by setting
# env.agents.<object name>.custom.frequency directly for each object.

defaults:
  # Use one maze for the time being
  - /env/mazes@env.mazes.maze: OPEN

  # Use the maze_task config as the base
  - maze_task

  # Define one point agent with a single eye
  - /env/agents@env.agents.agent_prey: prey
  - /env/agents/eyes@env.agents.agent_prey.eyes.eye: multi_eye

  - /env/agents@env.agents.agent_predator: predator
  - /env/agents/eyes@env.agents.agent_predator.eyes.eye: multi_eye

env:
  mazes:
    maze:
      scale: 2.0
      agent_id_map:
        A1: ${glob:agent_predator,${oc.dict.keys:env.agents}}
        A2: ${glob:agent_prey,${oc.dict.keys:env.agents}}

  reward_fn:
    reward_if_predator_done:
      _target_: cambrian.envs.reward_fns.reward_fn_done
      _partial_: true
      scale_by_quickness: true
      termination_reward: 5.0
      truncation_reward: -5.0
      disable_on_max_episode_steps: true
      for_agents: ${glob:agent_predator,${oc.dict.keys:env.agents}}

    reward_if_prey_done:
      _target_: cambrian.envs.reward_fns.reward_fn_done
      _partial_: true
      scale_by_quickness: false
      termination_reward: -5.0
      truncation_reward: 5.0
      disable_on_max_episode_steps: true
      for_agents: ${glob:agent_prey,${oc.dict.keys:env.agents}}

    penalize_if_has_contacts:
      _target_: cambrian.envs.reward_fns.reward_fn_has_contacts
      _partial_: true
      reward: -0.1
      for_agents: ${glob:agent_*,${oc.dict.keys:env.agents}}

    # penalize_time:
    #   _target_: cambrian.envs.reward_fns.reward_fn_constant
    #   _partial_: true
    #   reward: 1.0
    #   for_agents: ${glob:agent_prey,${oc.dict.keys:env.agents}}

  termination_fn:
    terminate_if_close_to_goal:
      _target_: cambrian.envs.done_fns.done_if_close_to_agents
      _partial_: true
      for_agents: ${glob:agent_*,${oc.dict.keys:env.agents}}
      to_agents: ${glob:agent_*,${oc.dict.keys:env.agents}}
      distance_threshold: 1.0

  truncation_fn:
    truncate_if_exceeds_max_episode_steps:
      _target_: cambrian.envs.done_fns.done_if_exceeds_max_episode_steps
      _partial_: true

eval_env:
  reward_fn:
    reward_if_predator_done:
      _target_: cambrian.envs.reward_fns.reward_fn_done
      _partial_: true
      scale_by_quickness: true
      termination_reward: 5.0
      truncation_reward: -5.0
      disable_on_max_episode_steps: true
      for_agents: ${glob:agent_predator,${oc.dict.keys:env.agents}}

    reward_if_prey_done:
      _target_: cambrian.envs.reward_fns.reward_fn_done
      _partial_: true
      scale_by_quickness: true
      termination_reward: -5.0
      truncation_reward: 5.0
      disable_on_max_episode_steps: true
      for_agents: ${glob:agent_prey,${oc.dict.keys:env.agents}}

    penalize_if_has_contacts:
      _target_: cambrian.envs.reward_fns.reward_fn_has_contacts
      _partial_: true
      reward: -0.1
      for_agents: ${glob:agent_*,${oc.dict.keys:env.agents}}

    # penalize_time:
    #   _target_: cambrian.envs.reward_fns.reward_fn_constant
    #   _partial_: true
    #   reward: 1.0
    #   for_agents: ${glob:agent_prey,${oc.dict.keys:env.agents}}

  termination_fn:
    terminate_if_close_to_goal:
      _target_: cambrian.envs.done_fns.done_if_close_to_agents
      _partial_: true
      for_agents: ${glob:agent_*,${oc.dict.keys:env.agents}}
      to_agents: ${glob:agent_*,${oc.dict.keys:env.agents}}
      distance_threshold: 1.0

  truncation_fn:
    truncate_if_exceeds_max_episode_steps:
      _target_: cambrian.envs.done_fns.done_if_exceeds_max_episode_steps
      _partial_: true
