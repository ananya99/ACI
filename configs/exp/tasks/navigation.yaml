# @package _global_

# This task is for navigation. It defines a set of mazes which the agent must navigate.
# The agent is rewarded based on it's movement from its initial position. The agent
# is penalized if it makes contact with the walls of the maze. A
# termination condition indicates success, and in this case, the agent is successful if
# it reaches the goal (within a certain distance threshold).

defaults:
  - /exp/tasks/task

  # Use one fairly complicated maze
  - /env/mazes@env.mazes.maze: COMPLEX
  - /env/mazes@eval_env.mazes.maze: COMPLEX_LARGE

  # Use the maze_exp config as the base
  - /exp/maze_exp

  # Define one point agent with a single eye
  - /env/agents@env.agents.agent: point
  - /env/agents/eyes@env.agents.agent.eyes.eye: eye

  # Define one goal object
  - /env/agents@env.agents.goal: object_sphere_goal

trainer:
  total_timesteps: 300_000

env:
  agents:
    goal:
      custom:
        size: 0.25

    agent:
      # Set the initial yaw to -pi / 4.
      init_quat: ["${eval:'math.cos(-math.pi/4)'}", 0, 0, "${eval:'math.sin(-math.pi/4)'}"]


  # Update the scale of the maze so that it's more difficult
  mazes:
    maze:
      scale: 2.0

      agent_id_map:
        default: [agent]
        E: [agent]
        O: [goal]

  reward_fn:
    reward_for_termination:
      for_agents: [agent]
      reward: 1.0
    reward_for_truncation:
      for_agents: [agent]
      reward: -1.0

    euclidean_delta_from_init:
      _target_: cambrian.envs.reward_fns.euclidean_delta_from_init
      _partial_: true
      factor: 1.0

    penalize_if_has_contacts:
      _target_: cambrian.envs.reward_fns.penalize_if_has_contacts
      _partial_: true
      penalty: -1.0
      for_agents: [agent]

  truncation_fn:
    truncate_if_low_reward:
      _target_: cambrian.envs.done_fns.done_if_low_reward
      _partial_: true
      threshold: -50.0

  termination_fn:
    terminate_if_close_to_goal:
      _target_: cambrian.envs.done_fns.done_if_close_to_agents
      _partial_: true
      for_agents: ${glob:goal*,${oc.dict.keys:env.agents}}
      distance_threshold: 1.0

eval_env:
  mazes:
    maze:
      agent_id_map:
        # Update the default map such that the agent is only placed on R:E spaces
        default: []
        E: [agent]
        O: [goal]

  step_fn:
    # respawn the goal if the agent is close to it
    respawn_objects_if_agent_close:
      _target_: cambrian.envs.step_fns.step_respawn_agents_if_close_to_agents
      _partial_: true
      for_agents: ${glob:goal*,${oc.dict.keys:env.agents}}
      to_agents: [agent]
      distance_threshold: 1.0

  reward_fn:
    reward_if_goal_respawned:
      _target_: cambrian.envs.reward_fns.reward_if_agents_respawned
      _partial_: true
      # large positive reward for respawning the goal (which happens if the agent is
      # close to it)
      reward: ${env.reward_fn.reward_for_termination.reward}
      for_agents: ${glob:goal*,${oc.dict.keys:env.agents}}

  truncation_fn:
    truncate_if_low_reward:
      threshold: -.inf
