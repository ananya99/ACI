# @package _global_

# This task is supposed to resemble a prey-like scenario, where an adversarial object
# is chasing the agent.

defaults:
  # Use one maze for the time being
  - /env/mazes@env.mazes.maze: OPEN

  # Use the maze_exp config as the base
  - /exp/maze_exp

  # Define one agent which will be trainable
  - /env/agents@env.agents.agent: point
  - /env/agents/eyes@env.agents.agent.eyes.eye: eye

  # Define an adversarial predator which tries to catch the agent
  - /env/agents@env.agents.adversary: point_predator_textured

custom:
  # Sets the frequency of the texture of the goal. Easier to override.
  frequency: 8

trainer:
  total_timesteps: 500_000
  max_episode_steps: 128 # shorten the episode length

env:
  mazes:
    maze:
      agent_id_map:
        default: [agent]
        O: [adversary]

  agents:
    adversary:
      overlay_color: [0.8, 0.2, 0.2, 1]
      custom:
        frequency: ${custom.frequency}

      instance:
        use_optimal_trajectory: false

  reward_fn:
    penalize_if_has_contacts:
      _target_: cambrian.envs.reward_fns.penalize_if_has_contacts
      _partial_: true
      penalty: -1.0
      for_agents: [agent]

    penalize_euclidean_delta_to_agent:
      _target_: cambrian.envs.reward_fns.reward_euclidean_delta_to_agents
      _partial_: true
      factor: -0.25
      agents: [agent]
      for_agents: [adversary]

  truncation_fn:
    truncate_if_close_to_adversary:
      _target_: cambrian.envs.done_fns.done_if_close_to_agents
      _partial_: true
      distance_threshold: 1.0
      agents: [adversary]
      for_agents: [agent]
