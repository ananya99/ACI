# @package _global_

# This task is for tracking of an object. It's similar to detection, but the object(s)
# are treated as 'agents' which move.

defaults:
  # Use one maze for the time being
  - /env/mazes/OPEN@env.mazes.OPEN

  # Use the maze_exp config as the base
  - /exp/maze_exp

  # Define one agent which will be trainable
  - /env/agents@env.agents.agent: ${env/agents}
  - /env/agents/eyes@env.agents.agent.eyes.eye: ${env/agents/eyes}

  # Then define a second "agent" which is really the object to track
  # It has no eyes
  - /env/agents@env.agents.goal: point_random

  - override /env/agents: point

trainer:
  total_timesteps: 500_000
  max_episode_steps: 128 # shorten the episode length

env:
  reward_fn:
    penalize_if_has_contacts:
      _target_: cambrian.envs.reward_fns.penalize_if_has_contacts
      _partial_: true
      penalty: -1.0
      agents: [agent]

    reward_euclidean_delta_to_object:
      _target_: cambrian.envs.reward_fns.reward_euclidean_delta_to_agents
      _partial_: true
      factor: 0.25
      agents: [goal]

    reward_for_termination:
      _target_: cambrian.envs.reward_fns.reward_for_termination
      _partial_: true
      reward: 5.0

    reward_for_truncation:
      _target_: cambrian.envs.reward_fns.reward_for_truncation
      _partial_: true
      reward: -10.0

  termination_fn:
    # Terminate (i.e. succeed) if the agent is close to the goal
    terminate_if_close_to_goal:
      _target_: cambrian.envs.done_fns.done_if_close_to_agents
      _partial_: true
      agents: [goal]
      distance_threshold: 1.0
