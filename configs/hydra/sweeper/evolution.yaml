defaults:
  # We use nevergrad for the evolution strategy
  - /hydra/sweeper/nevergrad@_here_

# NOTE: nevergrad is _not_ asynchronous in that it will wait until all workers are
# finished before selecting the next parameters to optimize over. For example, when
# using the submitit_slurm launcher with num_workers=4, all 4 jobs will be run and
# synchronously waited for all to finish until moving on. This may not be desired.
# Possible work arounds:
# 1. use a different launcher which requires one worker from the sweeper
#    this would involve writing a custom launcher tho I think
# 2. run more workers than the number of jobs you want to run in parallel. this means
#    they will effectively wait in the queue until the next job is ready to run
#    which is kind of asynchronous. Problem would be that each job that is queued
#    wasn't "intellegently" selected by the sweeper.
# 3. make a PR for hydra adding support for asynchronous launches. See this comment:
#    https://github.com/facebookresearch/hydra/blame/main/plugins/\
#       hydra_nevergrad_sweeper/hydra_plugins/hydra_nevergrad_sweeper/_impl.py#L162

optim:
  # For reproducibility, we set the seed to the same value as the one used in the
  # base config.
  seed: ${seed}

  # Here we assume we want to maximize the fitness returned by trainer. This may not
  # always be the case, but can be overridden in the downstream configs.
  maximize: true

  # We set the number of workers here to be 1. This means that the launcher will only
  # ever launch 1 job at a time. On a cluster where we want jobs to be run in parallel,
  # we can set this to a higher number.
  num_workers: 1

  # We expect the same input parameters to produce different output fitness due to
  # seeds and randomness in the training process. Therefore, we set noisy to true.
  noisy: true

  # The budget is the number of evaluations we want to run. The default is 80, set to
  # 100 just for fun.
  budget: 100
