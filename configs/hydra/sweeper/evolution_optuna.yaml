defaults:
  # We use optuna for the evolution strategy
  - /hydra/sweeper/optuna@_here_

  # This defines the sampler. Use NSGAII for the optimization algorithm.
  - override sampler: nsgaii

# NOTE: hydra sweepers are _not_ asynchronous in that it will wait until all workers are
# finished before selecting the next parameters to optimize over. For example, when
# using the submitit_slurm launcher with num_workers=4, all 4 jobs will be run and
# synchronously waited for all to finish until moving on. This may not be desired.
# Possible work arounds:
# 1. use a different launcher which requires one worker from the sweeper
#    this would involve writing a custom launcher tho I think
# 2. run more workers than the number of jobs you want to run in parallel. this means
#    they will effectively wait in the queue until the next job is ready to run
#    which is kind of asynchronous. Problem would be that each job that is queued
#    wasn't "intellegently" selected by the sweeper.
# 3. make a PR for hydra adding support for asynchronous launches. See this comment:
#    https://github.com/facebookresearch/hydra/blame/main/plugins/\
#       hydra_nevergrad_sweeper/hydra_plugins/hydra_nevergrad_sweeper/_impl.py#L162

study_name: ${expname}

sampler:
  # This seed is only used at the very beginning and is used for reproducibility of the
  # algorithm, not of the individual runs. We'll set it to 0 here instead of
  # ${seed} because otherwise we get an error saying that the hydra config is unset
  # since the sweeper is evaluated before the hydra config is parsed/set.
  seed: 0

  # Set the population size to the number of parallel workers. This is because we want
  # to evaluate all the workers in parallel and then select the next generation.
  population_size: ${eval:'${..n_jobs} if ${..n_jobs} > 1 else 2'}

  # Probability of mutating each parameter when creating a new individual.
  mutation_prob: null # use optuna defaults

  # This is the probability that a crossover (parameters swapping between parents) will
  # occur when creating a new individual.
  crossover_prob: 0.9

  # This is the probability of swapping each parameter of the parents during corssover.
  swapping_prob: 0.5

# Here we assume we want to maximize the fitness returned by trainer. This may not
# always be the case, but can be overridden in the downstream configs.
direction: maximize

# The budget is the number of evaluations we want to run. The total number of
# generations is the budget divided by the number of workers. We'll set the
# number generations and calculate the budget from that. Default generations to 20.
# NOTE: If budget is not a direct multiple of num_workers, at the end, the sweeper
# will run the remaining number of workers to reach the budget, which messes with
# our current generation calculation.
# NOTE #2: Some algorithms use the budget and num_workers as part of the optimization
# to know how exploratory to be. So be careful setting this number very large with
# the intention of stopping early.
n_trials: ${eval:'int(${oc.select:custom.variables.num_generations, 20} * ${.n_jobs})'}

# This defines the number of a parallel candidates you want to test at one time.
# This will default to 1 for most launchers. If the launcher is submitit, it will
# evaluate to batch_size * array_parallelism, which is basically the number of
# parallel jobs to run on each node * number of total nodes.
n_jobs: |
    ${eval:'${oc.select:hydra.launcher.tasks_per_node, 1} * ${oc.select:hydra.launcher.array_parallelism, 1}'}

# Set the max failures to be equivalent to one node's worth of workers. This is
# because if one node fails, we want to be able to restart the job with the same
# parameters on a different node.
max_failure_rate: ${eval:'1 / ${oc.select:hydra.launcher.array_parallelism, 1}'}
